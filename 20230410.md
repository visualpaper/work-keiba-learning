20230410_binary_model_wide

10000000 train

※ 途中停止したので嘘かも

```
    def _observe(self):
        # 1 レースを取得し、observe 化 (20 行固定) する。
        self._race = self._groups[self._steps]
        self._race.reset_index(inplace=True, drop=True)
        # padding_df = self._race.reindex(range(5), fill_value=-1)
        padding_df = self._race[["odds", "pred"]].reindex(range(20), fill_value=-1)
        # print(padding_df.values.tolist())
        return padding_df.values.tolist()


try:
    model = keras.models.load_model('./../model/binary_model_wide')
except:
    print("create")
    # Kerasを使ってモデルを作成します。
    model = keras.models.Sequential([
        keras.layers.Flatten(input_shape=(1,) + env.observation_space.shape),
        keras.layers.Dense(256, activation="elu"),
        keras.layers.Dense(256, activation='elu'),
        keras.layers.BatchNormalization(),
        keras.layers.Dense(256, activation='elu'),
        keras.layers.Dense(256, activation='elu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(nb_actions, activation="linear"),
    ])

model.summary()
    
# 経験値を蓄積するためのメモリです。学習を安定させるために使用します。
memory = SequentialMemory(limit=50000, window_length=1)

# 行動ポリシーはBoltzmannQPolicyを使用しています。
# EpsGreedyQPolicyと比較して、こちらの方が収束が早かったので採用しています。
policy = EpsGreedyQPolicy()

# DQNAgentを作成します。
dqn = DQNAgent(
    model=model,
    nb_actions=nb_actions,
    memory=memory,
    target_model_update=1e-2,
    policy=policy)

# DQNAgentのコンパイル。最適化はAdam,評価関数はMAEを使用します。
dqn.compile(Adam(learning_rate=1e-4), metrics=[
    keras.losses.BinaryCrossentropy(from_logits=True, name='binary_crossentropy'), 'accuracy'
])

# 学習開始
history = dqn.fit(env, nb_steps=10000000, visualize=False, log_interval=34462, verbose=1)


Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 40)                0         
                                                                 
 dense (Dense)               (None, 256)               10496     
                                                                 
 dense_1 (Dense)             (None, 256)               65792     
                                                                 
 batch_normalization (BatchN  (None, 256)              1024      
 ormalization)                                                   
                                                                 
 dense_2 (Dense)             (None, 256)               65792     
                                                                 
 dense_3 (Dense)             (None, 256)               65792     
                                                                 
 dropout (Dropout)           (None, 256)               0         
                                                                 
 dense_4 (Dense)             (None, 7)                 1799      
                                                                 
=================================================================
Total params: 210,695
Trainable params: 210,183
Non-trainable params: 512

[3778.0, 5294.0, 5422.0, 5734.0, 5554.0, 5634.0, 5418.0, 5676.0, 5394.0, 5474.0, 4950.0, 5560.0, 5566.0, 5318.0, 5560.0, 5638.0, 5470.0, 5858.0, 5856.0, 5766.0, 5450.0, 5396.0, 5904.0, 5820.0, 6042.0, 5948.0, 6112.0, 6140.0, 5974.0, 5934.0, 5784.0, 5748.0, 6056.0, 5940.0, 5888.0, 6130.0, 5952.0, 6198.0, 5780.0, 5780.0, 5408.0, 5882.0, 5832.0, 5360.0, 5678.0, 6108.0, 5494.0, 5372.0, 5844.0, 6060.0, 6190.0, 5894.0, 5558.0, 6152.0, 6226.0, 6104.0, 6114.0, 6076.0, 6032.0, 6074.0, 5724.0, 6204.0, 5958.0, 6152.0, 5752.0, 6090.0, 6002.0, 5360.0, 5948.0, 5564.0, 5572.0, 5396.0, 5802.0, 5772.0, 5964.0, 5970.0, 5936.0, 6134.0, 5330.0, 5670.0, 5592.0, 5588.0, 5734.0, 5488.0, 5398.0, 5762.0, 4864.0, 5072.0, 5614.0, 5950.0, 5992.0, 5916.0, 5450.0, 6014.0, 5884.0, 5962.0, 5904.0, 6006.0, 6424.0, 5636.0, 5052.0, 5638.0, 5670.0, 4130.0, 4482.0, 5726.0, 4736.0, 6078.0, 5970.0, 5498.0, 5910.0, 5954.0, 6058.0, 6152.0, 5976.0, 6128.0, 6088.0, 6218.0, 6278.0, 6260.0, 6152.0, 5944.0, 3972.0, 5272.0, 6270.0, 6502.0, 6120.0, 5736.0, 6108.0, 6668.0, 6650.0, 6612.0, 6736.0, 6224.0, 6466.0, 6378.0, 6268.0, 6550.0, 6456.0, 6486.0, 6482.0, 6272.0, 6688.0, 6618.0, 6562.0, 6202.0, 6446.0, 6672.0, 6494.0, 6620.0, 6442.0, 6460.0, 6780.0, 6708.0, 6684.0, 6856.0, 6812.0, 6702.0, 6876.0, 7204.0, 6836.0, 6672.0, 6048.0, 6216.0, 6546.0, 6510.0, 6304.0, 6528.0, 5802.0, 5930.0, 5726.0, 5606.0, 5408.0, 5560.0, 5786.0, 5860.0, 5892.0, 5956.0, 5924.0, 6228.0, 6270.0, 6184.0, 6200.0, 6266.0, 6464.0, 6440.0, 6554.0, 6584.0, 6700.0, 6856.0, 6882.0, 6898.0, 6916.0, 6940.0, 6766.0, 7022.0, 7310.0, 7244.0, 7366.0, 7424.0, 7564.0, 7394.0, 7464.0, 7174.0, 6804.0, 6144.0, 5758.0, 5492.0, 5610.0, 5478.0, 3850.0, 5620.0, 5856.0, 6106.0, 6696.0, 6912.0, 6872.0, 7052.0, 6882.0, 6608.0, 6550.0, 6308.0, 6542.0, 6688.0, 7012.0, 6924.0, 7210.0, 7236.0, 7162.0, 6694.0, 6952.0, 7144.0, 7406.0, 7458.0, 7482.0, 7508.0, 7498.0, 7584.0, 7562.0, 7332.0, 7068.0, 7324.0, 7284.0, 7306.0, 7502.0, 7388.0, 7486.0, 7370.0, 7224.0, 7594.0, 7510.0, 7388.0, 7216.0, 7292.0, 7228.0, 7280.0, 7510.0, 7338.0, 7222.0, 7410.0, 7262.0, 7466.0, 7422.0, 7124.0, 7320.0, 7476.0, 7408.0, 7438.0, 7518.0, 7240.0, 7216.0, 7566.0, 7282.0, 7142.0, 6930.0, 7212.0, 6994.0, 6898.0, 6894.0, 7028.0, 7164.0, 7258.0, 7324.0, 7064.0, 7290.0, 7318.0, 7290.0, 7286.0, 7216.0, 7428.0]
```

<br><br>

* 2013 予想

```
RANK_ONE_TWO_HORSE            :         -36300円 的中率 27.18%   回収率 81.38%   (53/195)
RANK_ONE_THREE_HORSE          :         -29800円 的中率 25.61%   回収率 63.66%   (21/82)
RANK_ONE_FOUR_HORSE           :         -40900円 的中率 23.97%   回収率 71.99%   (35/146)
RANK_ONE_FIVE_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_THREE_HORSE          :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_FOUR_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
NO_ACITON                     :              0円 的中率 66.35%   回収率 0.00%    (2011/3031)
TOTAL                         :        -107000円 的中率 25.77%   回収率 74.70%   (109/423)
```

<br>

* 2014 年予想

```
RANK_ONE_TWO_HORSE            :         -61000円 的中率 21.94%   回収率 68.88%   (43/196)
RANK_ONE_THREE_HORSE          :          20500円 的中率 29.52%   回収率 119.52%  (31/105)
RANK_ONE_FOUR_HORSE           :         -30000円 的中率 24.60%   回収率 76.19%   (31/126)
RANK_ONE_FIVE_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_THREE_HORSE          :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_FOUR_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
NO_ACITON                     :              0円 的中率 68.22%   回収率 0.00%    (2063/3024)
TOTAL                         :         -70500円 的中率 24.59%   回収率 83.49%   (105/427)
```

<br>

* 2015 年予想

```
RANK_ONE_TWO_HORSE            :         -60400円 的中率 24.24%   回収率 63.39%   (40/165)
RANK_ONE_THREE_HORSE          :          -9900円 的中率 32.22%   回収率 89.00%   (29/90)
RANK_ONE_FOUR_HORSE           :         -40200円 的中率 22.63%   回収率 70.66%   (31/137)
RANK_ONE_FIVE_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_THREE_HORSE          :              0円 的中率 0.00%    回収率 0.00%    (0/0)
RANK_TWO_FOUR_HORSE           :              0円 的中率 0.00%    回収率 0.00%    (0/0)
NO_ACITON                     :              0円 的中率 67.99%   回収率 0.00%    (2082/3062)
TOTAL                         :        -110500円 的中率 25.51%   回収率 71.81%   (100/392)
```
